# ðŸ§  PavilionAI: Dynamic LLM Agent
> **Bridging the gap between LLMs and Real-Time Data through Intelligent Tool Calling.**

[![Node.js](https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)](https://nodejs.org/)
[![Groq](https://img.shields.io/badge/Groq-f55036?style=for-the-badge&logo=lightning&logoColor=white)](https://groq.com/)
[![LLaMA 3.3](https://img.shields.io/badge/LLaMA%203.3-04100b?style=for-the-badge&logo=meta&logoColor=white)](https://ai.meta.com/)

**PavilionAI** is a high-performance Agentic AI implementation that solves the "hallucination problem." By leveraging **LLaMA 3.3 70B** and the **Tavily Web Search API**, this assistant intelligently decides when to stop "thinking" and start "searching."

---

## ðŸš€ Key Capabilities

* **ðŸŽ¯ Zero-Shot Tool Selection:** Automatically detects if a query requires external data.
* **ðŸŒ Real-Time Grounding:** Fetches live data to answer questions about current events (e.g., sports scores, news, or stock prices).
* **âš™ï¸ Deterministic Execution:** Configured with `temperature: 0` for consistent, reliable logic.
* **ðŸ—ï¸ Schema-First Design:** Uses structured JSON Schema for robust function parameter passing.

---

## ðŸ› ï¸ Tech Stack

| Component | Technology | Role |
| :--- | :--- | :--- |
| **Model** | LLaMA 3.3 70B | The "Brain" (Reasoning & Intent) |
| **Inference** | Groq SDK | Lightning-fast LLM execution |
| **Search Engine** | Tavily API | Real-time Web Search optimized for LLMs |
| **Runtime** | Node.js | System orchestration & Tool execution |

---

## ðŸ—ï¸ Architecture: How It Works

```mermaid
graph TD
    A[User Query] --> B{LLM Reasoning}
    B -- Needs Data? --> C[Generate Tool Call]
    C --> D[Node.js Function Execution]
    D --> E[Tavily Search API]
    E --> F[Contextual Results]
    F --> G[LLM Final Synthesis]
    B -- Knowledge Sufficient? --> H[Direct Response]
    G --> I[Final Answer to User]
